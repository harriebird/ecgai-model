{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c537fa59-712f-4705-8e37-5aaea403e3cd",
   "metadata": {},
   "source": [
    "# ecgai-model\n",
    "ECG (electrocardiogram) classification using Artificial Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769c6e67-812d-4780-b9ef-6ffa42e4ffd9",
   "metadata": {},
   "source": [
    "## Load the required modules\n",
    "This loads the required modules to be used in the data preparation, training,\n",
    "and testing of the model. Make sure to install the libraries from before\n",
    "proceeding to this step. If libraries were not yet installed, use the command\n",
    "`pip install -r requirements.txt`. The command will install those libraries listed in\n",
    "the `requirements.txt` file along with its specific versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45591f0a-a39c-427b-b080-bd1a368e66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23498aae-3703-454c-b231-dd3f2077b4e4",
   "metadata": {},
   "source": [
    "## Load the ECG dataset CSV files\n",
    "The [ECG Heartbeat Categorization Dataset](https://www.kaggle.com/datasets/shayanfazeli/heartbeat)\n",
    "was downloaded from Kaggle. This dataset from Kaggle contains a simplified\n",
    "CSV version of datasets from [MIT-BIH Arrhythmia Database](https://www.physionet.org/content/mitdb/1.0.0/)\n",
    "and [PTB Diagnostic ECG Database](https://www.physionet.org/content/ptbdb/1.0.0/).\n",
    "For this project, the MIT-BIH Arrhythmia Database is used as the dataset for the training and testing.\n",
    "Download and unzip the file. Once the extraction is done,\n",
    "copy the files `mitbih_train.csv` and `mitbih_test.csv` inside the `dataset` directory.\n",
    "\n",
    "The code in the next cell displays the line chart of the first record for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32594fd9-4729-4aee-b38d-32466e4f48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/mitbih_train.csv', header=None)\n",
    "test_df = pd.read_csv('dataset/mitbih_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe23bd60-d440-4fb3-b1fb-52a7a40c4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_df.iloc[200][:186])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7059ae5-4a54-43bc-9253-6326e8823781",
   "metadata": {},
   "source": [
    "## Resample the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b11fe94-9d19-484a-93c4-3c3f0a7101d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1=train_df[train_df[187]==1]\n",
    "df_2=train_df[train_df[187]==2]\n",
    "df_3=train_df[train_df[187]==3]\n",
    "df_4=train_df[train_df[187]==4]\n",
    "\n",
    "df_0=(train_df[train_df[187]==0]).sample(n=20000,random_state=42)\n",
    "df_1_resample=resample(df_1,replace=True,n_samples=20000,random_state=123)\n",
    "df_2_resample=resample(df_2,replace=True,n_samples=20000,random_state=124)\n",
    "df_3_resample=resample(df_3,replace=True,n_samples=20000,random_state=125)\n",
    "df_4_resample=resample(df_4,replace=True,n_samples=20000,random_state=126)\n",
    "\n",
    "train_df=pd.concat([df_0,df_1_resample,df_2_resample,df_3_resample,df_4_resample])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4606ce-38a3-4266-b11d-5170b29afe41",
   "metadata": {},
   "source": [
    "## Split the dataset into training, validation, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1da708-f9b0-4f79-8ab5-a49c30629f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_temp, y_train, y_temp = train_test_split(\n",
    "    train_df.drop([187], axis=1),\n",
    "    train_df[187],\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(\n",
    "    x_temp,\n",
    "    y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c7f3d-5984-4429-a595-21f8dbb89c6b",
   "metadata": {},
   "source": [
    "## Define the model layers\n",
    "![Model View](img/model.png)\n",
    "\n",
    "The image above is a visual representaiton of the model that is created by the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2960abfb-2d9d-4384-bbe9-ff3fce677133",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(187,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']          \n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8149a4-932b-49d5-9c8f-43c5cde9c4b8",
   "metadata": {},
   "source": [
    "## Let the training begin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ec80a-21a4-4e88-b50a-1113ab339b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=100, epochs=200, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eece0fe-71d8-427c-9b68-b51e47b0b1d8",
   "metadata": {},
   "source": [
    "## Visualize Training Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050b905c-f86c-43ba-b059-fe795a65fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (accuracy_chart, loss_chart) = plt.subplots(1, 2)\n",
    "fig.suptitle('Training Accuracy and Loss shits')\n",
    "accuracy_chart.set_title('Accuracy')\n",
    "loss_chart.set_title('Loss')\n",
    "\n",
    "accuracy_chart.plot(history.history['accuracy'])\n",
    "accuracy_chart.plot(history.history['val_accuracy'])\n",
    "accuracy_chart.legend([\"accuracy\",\"val_accuracy\"])\n",
    "accuracy_chart.set(xlabel='Epoch', ylabel='Accuracy')\n",
    "\n",
    "\n",
    "loss_chart.plot(history.history['loss'])\n",
    "loss_chart.plot(history.history['val_loss'])\n",
    "loss_chart.legend([\"loss\",\"val_loss\"])\n",
    "loss_chart.set(xlabel='Epoch', ylabel='Loss')\n",
    "fig.set_figwidth(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1569ef57-1190-4c26-87f3-bb3f965f6751",
   "metadata": {},
   "source": [
    "## Determine Accuracy and generate a Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11207820-801e-4afb-8f2f-2ca06b14240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (cm_test, cm_external) = plt.subplots(1, 2)\n",
    "fig.suptitle('Confusion Matrix')\n",
    "cm_test.set_title('From Test Split')\n",
    "cm_external.set_title('From Test File')\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "test_pred_labels = np.argmax(y_pred, axis=1)\n",
    "test_accuracy = accuracy_score(y_test, test_pred_labels)\n",
    "print(\"Accuracy using the test split: {}\".format(test_accuracy))\n",
    "\n",
    "cm = confusion_matrix(y_test, test_pred_labels)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "\n",
    "x_external = test_df.drop([187], axis=1)\n",
    "y_external = test_df[187]\n",
    "y_pred = model.predict(x_external)\n",
    "test_pred_labels = np.argmax(y_pred, axis=1)\n",
    "test_accuracy = accuracy_score(y_external, test_pred_labels)\n",
    "print(\"Accuracy using the test file: {}\".format(test_accuracy))\n",
    "cm = confusion_matrix(y_external, test_pred_labels)\n",
    "cm_external_display = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "cm_display.plot(ax=cm_test)\n",
    "cm_external_display.plot(ax=cm_external)\n",
    "fig.set_figwidth(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2febdb-ba83-41e0-b201-31fad0b5aec3",
   "metadata": {},
   "source": [
    "## Save the trained model\n",
    "After the training and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b18e4-a36a-484a-8c9c-ca8222d1bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af2ffa-67fd-4d92-b74f-8598191c740f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
